{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc7TPeLL3IIj"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('brown')\n",
        "nltk.download('reuters')\n",
        "nltk.download('names')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "import nltk\n",
        "from nltk.corpus import inaugural\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "GKT1ljKo_tmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 5\n"
      ],
      "metadata": {
        "id": "WhF6GrXH6Qz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tWrite a Python program using NLTK to perform part-of-speech tagging on the sentence: \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NSCYgHt8528I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize and perform POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(\"POS Tags:\", pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8KBjrXG6v6A",
        "outputId": "f26c9b0c-a25c-4ea4-aab7-6a17a7c8a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tUsing NLTK, write a function that takes a list of sentences and returns a list of part-of-speech tagged sentences.\n"
      ],
      "metadata": {
        "id": "icO9pkaq6ixy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pos_tag_sentences(sentences):\n",
        "    tagged_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        tagged_sentences.append(nltk.pos_tag(tokens))\n",
        "\n",
        "    return tagged_sentences\n",
        "\n",
        "# Test the function with a list of sentences\n",
        "sentences = [\"The quick brown fox jumps over the lazy dog.\", \"NLTK is a leading toolkit for text processing.\"]\n",
        "result = pos_tag_sentences(sentences)\n",
        "for sentence, tags in zip(sentences, result):\n",
        "    print(f\"Sentence: {sentence}\\nPOS Tags: {tags}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnv5SVAs6wa4",
        "outputId": "13c8c8d2-9c41-4e91-eb2f-dd5b81961dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The quick brown fox jumps over the lazy dog.\n",
            "POS Tags: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n",
            "\n",
            "Sentence: NLTK is a leading toolkit for text processing.\n",
            "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('leading', 'JJ'), ('toolkit', 'NN'), ('for', 'IN'), ('text', 'NN'), ('processing', 'NN'), ('.', '.')]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tExplain how to map the Penn Treebank POS tags to the Universal POS tags using NLTK. Provide a code example that tags a sentence and maps the tags accordingly.\n"
      ],
      "metadata": {
        "id": "9Vj8pPTF6j2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a mapping function\n",
        "def map_penn_to_universal(tag):\n",
        "    penn_to_universal = {\n",
        "        'NN': 'NOUN', 'NNS': 'NOUN', 'NNPS': 'NOUN', 'NNP': 'NOUN',\n",
        "        'VB': 'VERB', 'VBD': 'VERB', 'VBG': 'VERB', 'VBN': 'VERB', 'VBP': 'VERB', 'VBZ': 'VERB',\n",
        "        'JJ': 'ADJ', 'JJR': 'ADJ', 'JJS': 'ADJ',\n",
        "        'RB': 'ADV', 'RBR': 'ADV', 'RBS': 'ADV',\n",
        "        'DT': 'DET', 'PRP': 'PRON', 'PRP$': 'PRON', 'POS': 'PRON',\n",
        "        'IN': 'ADP', 'CC': 'CONJ', 'CD': 'NUM', 'UH': 'INTJ', 'WP': 'PRON', 'WP$': 'PRON'\n",
        "    }\n",
        "    return penn_to_universal.get(tag, 'X')  # Default 'X' for unknown tags\n",
        "\n",
        "# Example of POS tagging and mapping\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Map Penn Treebank tags to Universal POS tags\n",
        "universal_tags = [(word, map_penn_to_universal(tag)) for word, tag in pos_tags]\n",
        "print(\"Mapped Universal POS Tags:\", universal_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2sG-j7n6xAA",
        "outputId": "7f57d38c-9cbe-4a1f-edd5-43d3f0ba604e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Universal POS Tags: [('The', 'DET'), ('quick', 'ADJ'), ('brown', 'NOUN'), ('fox', 'NOUN'), ('jumps', 'VERB'), ('over', 'ADP'), ('the', 'DET'), ('lazy', 'ADJ'), ('dog', 'NOUN'), ('.', 'X')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\tWrite a Python function using NLTK that takes a sentence as input and returns a list of all nouns in the sentence.\n"
      ],
      "metadata": {
        "id": "FavsOckV6kz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_nouns(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Extract nouns (NN, NNS, NNP, NNPS)\n",
        "    nouns = [word for word, tag in pos_tags if tag in ('NN', 'NNS', 'NNP', 'NNPS')]\n",
        "    return nouns\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "nouns = extract_nouns(sentence)\n",
        "print(\"Nouns in the sentence:\", nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Co49Fu6xi_",
        "outputId": "e8d2c97b-adf2-4056-b92f-56c83efbe82b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns in the sentence: ['brown', 'fox', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\tUsing the Brown Corpus in NLTK, write a program to find the most common part-of-speech tag in the news category.\n"
      ],
      "metadata": {
        "id": "ZMMBooL46mLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "# Filter sentences from the 'news' category\n",
        "news_sentences = brown.tagged_sents(categories='news')\n",
        "\n",
        "# Flatten the list of tagged words and count frequency\n",
        "flat_tags = [tag for sentence in news_sentences for word, tag in sentence]\n",
        "freq_dist = nltk.FreqDist(flat_tags)\n",
        "\n",
        "# Most common POS tag\n",
        "most_common_tag = freq_dist.max()\n",
        "print(\"Most common POS tag in the news category:\", most_common_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi7LX5946x-_",
        "outputId": "3c99d17d-8aa1-4aba-aed9-a4829589f04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common POS tag in the news category: NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\tWrite a Python program using NLTK to train a unigram part-of-speech tagger on the Brown Corpus and evaluate its accuracy.\n"
      ],
      "metadata": {
        "id": "jxfIn7x96nHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import DefaultTagger\n",
        "\n",
        "# Split the Brown corpus into training and test data\n",
        "train_sents = brown.tagged_sents(categories='news')[:int(len(brown.tagged_sents(categories='news')) * 0.8)]\n",
        "test_sents = brown.tagged_sents(categories='news')[int(len(brown.tagged_sents(categories='news')) * 0.8):]\n",
        "\n",
        "# Create a unigram tagger with a default tagger\n",
        "default_tagger = DefaultTagger('NN')\n",
        "unigram_tagger = UnigramTagger(train_sents, backoff=default_tagger)\n",
        "accuracy = unigram_tagger.accuracy(test_sents)\n",
        "print(\"Unigram POS Tagger Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOL5LAEe6yuA",
        "outputId": "35506782-4d66-423d-8f2c-34d688b10bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram POS Tagger Accuracy: 0.8267257575027699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.\tExplain the concept of backoff tagging in NLTK. Write a Python program that combines a bigram tagger with a unigram tagger as a backoff, and evaluate its performance on the Brown Corpus.\n"
      ],
      "metadata": {
        "id": "2LYhLhYj6n4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import BigramTagger\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import DefaultTagger\n",
        "\n",
        "# Create a bigram tagger with a unigram tagger as backoff\n",
        "bigram_tagger = BigramTagger(train_sents, backoff=unigram_tagger)\n",
        "\n",
        "# Evaluate the bigram tagger with backoff\n",
        "accuracy_both = bigram_tagger.accuracy(test_sents)\n",
        "print(\"Bigram and Unigram Backoff POS Tagger Accuracy:\", accuracy_both)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5BfmKUN6zH5",
        "outputId": "87161aff-d1d7-4156-e0a5-3d8c814a9f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram and Unigram Backoff POS Tagger Accuracy: 0.8360711016908329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.\tWrite a Python program to tag words with part-of-speech using NLTK and then extract all adjectives from the sentence: \"The beautiful sunset painted the sky with vibrant colors.\"\n"
      ],
      "metadata": {
        "id": "OvWHidx46ouH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sentence\n",
        "sentence = \"The beautiful sunset painted the sky with vibrant colors.\"\n",
        "\n",
        "# Tokenize and POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "# Extract adjectives (JJ, JJR, JJS)\n",
        "adjectives = [word for word, tag in pos_tags if tag in ('JJ', 'JJR', 'JJS')]\n",
        "\n",
        "print(\"Adjectives in the sentence:\", adjectives)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UJv8Fd6zPI",
        "outputId": "695f6df0-3e2b-417a-e3e5-2f74f82b4fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjectives in the sentence: ['beautiful', 'vibrant']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.\tWrite a Python program to calculate the frequency of each part-of-speech tag in a given text.\n"
      ],
      "metadata": {
        "id": "i0ebEXpy6pnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag the words in a text\n",
        "text = brown.words(categories='news')\n",
        "pos_tags = nltk.pos_tag(text)\n",
        "\n",
        "# Calculate frequency of each POS tag\n",
        "freq_dist = nltk.FreqDist(tag for word, tag in pos_tags)\n",
        "\n",
        "print(\"Frequency of each POS tag:\", freq_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmy2wroc6zW4",
        "outputId": "5b05f4a7-488d-416c-9dcb-506e93a0124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of each POS tag: <FreqDist with 41 samples and 100554 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.\tUsing NLTK, write a program that tags words in a sentence and prints only the verbs.\n"
      ],
      "metadata": {
        "id": "cSj6mEN86qaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract and print verbs\n",
        "def extract_verbs(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Extract verbs (VB, VBD, VBG, VBN, VBP, VBZ)\n",
        "    verbs = [word for word, tag in pos_tags if tag.startswith('VB')]\n",
        "    return verbs\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The beautiful sunset painted the sky with vibrant colors.\"\n",
        "verbs = extract_verbs(sentence)\n",
        "print(\"Verbs in the sentence:\", verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vTuTsRV6zcb",
        "outputId": "2f2e7a8c-1242-4c8a-890a-061c0df0951b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbs in the sentence: ['painted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.\tWrite a Python program using NLTK to identify and print all proper nouns from a given sentence.\n"
      ],
      "metadata": {
        "id": "THuFG1et6rRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract and print proper nouns\n",
        "def extract_proper_nouns(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Extract proper nouns (NNP, NNPS)\n",
        "    proper_nouns = [word for word, tag in pos_tags if tag in ('NNP', 'NNPS')]\n",
        "    return proper_nouns\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"Barack Obama gave a speech in Washington.\"\n",
        "proper_nouns = extract_proper_nouns(sentence)\n",
        "print(\"Proper Nouns in the sentence:\", proper_nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ80Wi7x6zgj",
        "outputId": "cf1668f5-70f6-46d7-9f3a-795c84e3a251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proper Nouns in the sentence: ['Barack', 'Obama', 'Washington']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.\tWrite a Python program to train a trigram part-of-speech tagger with a unigram backoff on the Brown corpus and evaluate its performance.\n"
      ],
      "metadata": {
        "id": "GtqfZJWi6sVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import UnigramTagger, TrigramTagger\n",
        "from nltk.corpus import brown\n",
        "\n",
        "# Split the Brown corpus into training and test data\n",
        "train_sents = brown.tagged_sents(categories='news')[:int(len(brown.tagged_sents(categories='news')) * 0.8)]\n",
        "test_sents = brown.tagged_sents(categories='news')[int(len(brown.tagged_sents(categories='news')) * 0.8):]\n",
        "\n",
        "# Train a unigram tagger\n",
        "unigram_tagger = UnigramTagger(train_sents)\n",
        "\n",
        "# Train a trigram tagger with unigram backoff\n",
        "trigram_tagger = TrigramTagger(train_sents, backoff=unigram_tagger)\n",
        "\n",
        "# Evaluate the trigram tagger with unigram backoff\n",
        "accuracy = trigram_tagger.accuracy(test_sents)\n",
        "print(\"Trigram POS Tagger with Unigram Backoff Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4dz7kbM6zlQ",
        "outputId": "5e028c79-ad74-4df5-9be1-7330d3aaf1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram POS Tagger with Unigram Backoff Accuracy: 0.8053374440001927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.\tWrite a Python program using NLTK to tag a sentence and count how many words belong to each part-of-speech category.\n"
      ],
      "metadata": {
        "id": "2r5KzZTD6tJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Function to count POS categories\n",
        "def count_pos_categories(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Calculate frequency of each POS tag\n",
        "    pos_freq = FreqDist(tag for word, tag in pos_tags)\n",
        "    return pos_freq\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "pos_count = count_pos_categories(sentence)\n",
        "print(\"POS category counts:\", pos_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9etUoVM36zqA",
        "outputId": "7e867502-6a74-4fe2-ab65-318915e9e62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS category counts: <FreqDist with 6 samples and 10 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.\tWrite a Python program to tag a given text with part-of-speech tags and then filter out only determiners (DT) using NLTK.\n"
      ],
      "metadata": {
        "id": "mTH6y7gn6uAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract determiners (DT)\n",
        "def extract_determiners(sentence):\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Extract determiners (DT)\n",
        "    determiners = [word for word, tag in pos_tags if tag == 'DT']\n",
        "    return determiners\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "determiners = extract_determiners(sentence)\n",
        "print(\"Determiners in the sentence:\", determiners)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaJ4gCA46zvw",
        "outputId": "5e9dbb15-eeee-4659-ed8b-fc5915bcc7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Determiners in the sentence: ['The', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.\tWrite a Python program to calculate and print the lexical diversity of nouns, verbs, adjectives, and adverbs in a given text."
      ],
      "metadata": {
        "id": "CD51dxYx6u03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Function to calculate lexical diversity for nouns, verbs, adjectives, and adverbs\n",
        "def lexical_diversity(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Extract words by POS categories\n",
        "    nouns = [word for word, tag in pos_tags if tag in ('NN', 'NNS', 'NNP', 'NNPS')]\n",
        "    verbs = [word for word, tag in pos_tags if tag.startswith('VB')]\n",
        "    adjectives = [word for word, tag in pos_tags if tag in ('JJ', 'JJR', 'JJS')]\n",
        "    adverbs = [word for word, tag in pos_tags if tag in ('RB', 'RBR', 'RBS')]\n",
        "\n",
        "    # Calculate lexical diversity (unique words / total words)\n",
        "    noun_diversity = len(set(nouns)) / len(nouns) if nouns else 0\n",
        "    verb_diversity = len(set(verbs)) / len(verbs) if verbs else 0\n",
        "    adj_diversity = len(set(adjectives)) / len(adjectives) if adjectives else 0\n",
        "    adv_diversity = len(set(adverbs)) / len(adverbs) if adverbs else 0\n",
        "\n",
        "    return {\n",
        "        'Noun Diversity': noun_diversity,\n",
        "        'Verb Diversity': verb_diversity,\n",
        "        'Adjective Diversity': adj_diversity,\n",
        "        'Adverb Diversity': adv_diversity\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"The quick brown fox jumps over the lazy dog, while the beautiful sunset paints the sky.\"\n",
        "lexical_div = lexical_diversity(text)\n",
        "print(\"Lexical Diversity:\", lexical_div)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_d-nZQq60EX",
        "outputId": "0ab544d9-d89d-49bd-b295-5093aab516f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexical Diversity: {'Noun Diversity': 1.0, 'Verb Diversity': 1.0, 'Adjective Diversity': 1.0, 'Adverb Diversity': 0}\n"
          ]
        }
      ]
    }
  ]
}