{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "Eo98DkxmEi7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tWrite a Python program using NLTK to define a context-free grammar (CFG) that can parse simple sentences like \"The cat sat on the mat.\" Use this grammar to generate the parse tree for the sentence.\n",
        "\n"
      ],
      "metadata": {
        "id": "YstogxHuAke8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# Define a context-free grammar (without comments)\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N\n",
        "    VP -> V PP | V\n",
        "    PP -> P NP\n",
        "    Det -> 'the'\n",
        "    N -> 'cat' | 'mat'\n",
        "    V -> 'sat'\n",
        "    P -> 'on'\n",
        "\"\"\")\n",
        "\n",
        "# Input sentence\n",
        "sentence = \"the cat sat on the mat\"\n",
        "\n",
        "# Tokenize the sentence into words\n",
        "tokens = sentence.split()\n",
        "\n",
        "# Create a parser using the defined grammar\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Parse the sentence and generate the parse tree\n",
        "print(\"Parse Tree:\")\n",
        "for tree in parser.parse(tokens):\n",
        "    print(tree)\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjjjdel4ETHR",
        "outputId": "58dd62d6-315c-424e-a5c8-69e7744731ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse Tree:\n",
            "(S\n",
            "  (NP (Det the) (N cat))\n",
            "  (VP (V sat) (PP (P on) (NP (Det the) (N mat)))))\n",
            "             S                     \n",
            "      _______|_______               \n",
            "     |               VP            \n",
            "     |        _______|___           \n",
            "     |       |           PP        \n",
            "     |       |    _______|___       \n",
            "     NP      |   |           NP    \n",
            "  ___|___    |   |        ___|___   \n",
            "Det      N   V   P      Det      N \n",
            " |       |   |   |       |       |  \n",
            "the     cat sat  on     the     mat\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tUsing NLTK, write a function that takes a sentence as input and returns all possible parse trees using a given CFG. Demonstrate this function with the sentence \"I saw the man with the telescope.\"\n"
      ],
      "metadata": {
        "id": "lAfULT9JETRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# Define a CFG\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Pronoun | Det N | Det N PP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  Pronoun -> 'I' | 'he' | 'she'\n",
        "  Det -> 'the' | 'a'\n",
        "  N -> 'man' | 'telescope'\n",
        "  V -> 'saw'\n",
        "  P -> 'with'\n",
        "\"\"\")\n",
        "\n",
        "# Function to return all parse trees\n",
        "def parse_all_trees(sentence):\n",
        "    parser = nltk.ChartParser(grammar)\n",
        "    trees = list(parser.parse(sentence))\n",
        "    return trees\n",
        "\n",
        "# Demonstrating with \"I saw the man with the telescope.\"\n",
        "sentence = ['I', 'saw', 'the', 'man', 'with', 'the', 'telescope']\n",
        "trees = parse_all_trees(sentence)\n",
        "\n",
        "# Display all parse trees\n",
        "for tree in trees:\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZ6V6a_EUHN",
        "outputId": "51195b74-ccde-4ef8-e68f-5e2dcc018d29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         S                                    \n",
            "    _____|___________                          \n",
            "   |                 VP                       \n",
            "   |      ___________|________                 \n",
            "   |     |       |            PP              \n",
            "   |     |       |        ____|___             \n",
            "   NP    |       NP      |        NP          \n",
            "   |     |    ___|___    |     ___|______      \n",
            "Pronoun  V  Det      N   P   Det         N    \n",
            "   |     |   |       |   |    |          |     \n",
            "   I    saw the     man with the     telescope\n",
            "\n",
            "         S                                \n",
            "    _____|_______                          \n",
            "   |             VP                       \n",
            "   |      _______|___                      \n",
            "   |     |           NP                   \n",
            "   |     |    _______|____                 \n",
            "   |     |   |   |        PP              \n",
            "   |     |   |   |    ____|___             \n",
            "   NP    |   |   |   |        NP          \n",
            "   |     |   |   |   |     ___|______      \n",
            "Pronoun  V  Det  N   P   Det         N    \n",
            "   |     |   |   |   |    |          |     \n",
            "   I    saw the man with the     telescope\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tWrite a Python program using NLTK to create a recursive descent parser for a given CFG. Parse the sentence \"She eats a sandwich.\" and display the parse tree.\n"
      ],
      "metadata": {
        "id": "MIJvIkIrEUNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# Define a CFG\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> Pronoun\n",
        "  VP -> V NP\n",
        "  Pronoun -> 'She'\n",
        "  V -> 'eats'\n",
        "  NP -> Det N\n",
        "  Det -> 'a'\n",
        "  N -> 'sandwich'\n",
        "\"\"\")\n",
        "\n",
        "# Recursive Descent Parser using NLTK's Top-Down ChartParser\n",
        "parser = nltk.ChartParser(grammar)\n",
        "\n",
        "# Sentence to parse\n",
        "sentence = ['She', 'eats', 'a', 'sandwich']\n",
        "\n",
        "# Parse and print the parse tree\n",
        "for tree in parser.parse(sentence):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UJXO0zqEVK8",
        "outputId": "a6370417-e26e-4638-d29b-45efda031467"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              S                  \n",
            "    __________|___                \n",
            "   |              VP             \n",
            "   |      ________|___            \n",
            "   NP    |            NP         \n",
            "   |     |         ___|_____      \n",
            "Pronoun  V       Det        N    \n",
            "   |     |        |         |     \n",
            "  She   eats      a      sandwich\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.\tUsing NLTK, write a program to extract noun phrases from a sentence using a chunk grammar. Apply it to the sentence \"The quick brown fox jumps over the lazy dog.\"\n"
      ],
      "metadata": {
        "id": "2Xa0w6PxEVQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "# Define a chunk grammar for noun phrases (NP)\n",
        "chunk_grammar = \"\"\"\n",
        "  NP: {<DT>?<JJ>*<NN.*>}   # Det, Adjective(s), Noun\n",
        "\"\"\"\n",
        "chunk_parser = nltk.RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Display the chunked tree\n",
        "tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvlVxCHwEWH0",
        "outputId": "b0baccbb-9478-4e8a-b0fc-45b68b3dbb01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                S                                          \n",
            "     ___________________________|_______________________________            \n",
            "    |        |     |            NP               NP             NP         \n",
            "    |        |     |     _______|________        |       _______|______     \n",
            "jumps/VBZ over/IN ./. The/DT quick/JJ brown/NN fox/NN the/DT lazy/JJ dog/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\tWrite a Python function using NLTK that takes a sentence as input and returns the verb phrases (VP) using a chunk grammar. Demonstrate this function with the sentence \"The cat is sleeping on the mat.\"\n"
      ],
      "metadata": {
        "id": "DSo2k7OgEWNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "# Define a chunk grammar for verb phrases (VP)\n",
        "chunk_grammar = \"\"\"\n",
        "  VP: {<VB.*><NP|PP|CLAUSE>*}    # Verb followed by NP, PP, or clauses\n",
        "\"\"\"\n",
        "chunk_parser = nltk.RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The cat is sleeping on the mat.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Display the chunked tree\n",
        "tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXf7usr5EW8u",
        "outputId": "d2cad18b-6b13-45ec-8550-8d4e7dd7384d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      S                                  \n",
            "   ___________________|___________________________        \n",
            "  |      |      |     |      |     |    VP        VP     \n",
            "  |      |      |     |      |     |    |         |       \n",
            "The/DT cat/NN on/IN the/DT mat/NN ./. is/VBZ sleeping/VBG\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\tWrite a Python program using NLTK to define a probabilistic context-free grammar (PCFG) and generate a parse tree for the sentence \"The cat sleeps.\"\n"
      ],
      "metadata": {
        "id": "s5uF-R46EXDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import PCFG\n",
        "\n",
        "# Define a Probabilistic Context-Free Grammar (PCFG)\n",
        "pcfg = PCFG.fromstring(\"\"\"\n",
        "  S -> NP VP [1.0]\n",
        "  NP -> Det N [1.0]\n",
        "  VP -> V [1.0]\n",
        "  Det -> 'The' [0.5] | 'a' [0.5]\n",
        "  N -> 'cat' [1.0]\n",
        "  V -> 'sleeps' [1.0]\n",
        "\"\"\")\n",
        "\n",
        "# Create a parser using the PCFG\n",
        "parser = nltk.ChartParser(pcfg)\n",
        "\n",
        "# Sentence to parse\n",
        "sentence = ['The', 'cat', 'sleeps']\n",
        "\n",
        "# Parse the sentence and print the tree\n",
        "for tree in parser.parse(sentence):\n",
        "    tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_LBZq3QEX0M",
        "outputId": "632458e2-5672-4d38-b255-8c3a354ea264"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         S        \n",
            "      ___|____     \n",
            "     NP       VP  \n",
            "  ___|___     |    \n",
            "Det      N    V   \n",
            " |       |    |    \n",
            "The     cat sleeps\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.\tWrite a Python program to visualize the chunk tree for a given sentence using a noun phrase chunking grammar.\n",
        ""
      ],
      "metadata": {
        "id": "RpGR-ER4EX5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Define a chunk grammar for noun phrases (NP)\n",
        "chunk_grammar = \"\"\"\n",
        "  NP: {<DT>?<JJ>*<NN.*>}  # Determiner (optional), Adjectives (optional), Noun\n",
        "\"\"\"\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Visualize the chunk tree\n",
        "tree.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqHgbzOoEYu2",
        "outputId": "3ec0397e-7b92-4662-bdf7-a15f38259980"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 S                                          \n",
            "     ____________________________|_______________________________            \n",
            "    |         |     |            NP               NP             NP         \n",
            "    |         |     |     _______|________        |       _______|______     \n",
            "jumped/VBD over/IN ./. The/DT quick/JJ brown/NN fox/NN the/DT lazy/JJ dog/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.\tWrite a Python program that extracts prepositional phrases (PP) from a given text using a chunking grammar.\n"
      ],
      "metadata": {
        "id": "sFZh6sq6EY0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define a chunk grammar for prepositional phrases (PP)\n",
        "chunk_grammar = r\"\"\"\n",
        "    PP: {<IN><DT>?<JJ>*<NN>}  # Prepositional phrase: preposition + optional determiner + adjectives + noun\n",
        "\"\"\"\n",
        "\n",
        "# Create a chunk parser\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Function to extract prepositional phrases\n",
        "def extract_prepositional_phrases(text):\n",
        "    # Tokenize and POS tag the text\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    # Parse the POS-tagged text using the chunk grammar\n",
        "    tree = chunk_parser.parse(pos_tags)\n",
        "\n",
        "    # Extract prepositional phrases\n",
        "    prepositional_phrases = []\n",
        "    for subtree in tree:\n",
        "        if isinstance(subtree, nltk.Tree) and subtree.label() == 'PP':\n",
        "            prepositional_phrases.append(\" \".join(word for word, pos in subtree.leaves()))\n",
        "\n",
        "    return prepositional_phrases\n",
        "\n",
        "# Input text\n",
        "text = \"The cat sat on the mat. The dog barked at the stranger in the park.\"\n",
        "\n",
        "# Extract prepositional phrases\n",
        "prepositional_phrases = extract_prepositional_phrases(text)\n",
        "\n",
        "# Print the extracted prepositional phrases\n",
        "print(\"Prepositional Phrases:\")\n",
        "for pp in prepositional_phrases:\n",
        "    print(pp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryhdveG9EZs2",
        "outputId": "d6874e77-5c3c-4730-9ff4-b380a9a55696"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepositional Phrases:\n",
            "on the mat\n",
            "at the stranger\n",
            "in the park\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.\tWrite a Python program that extracts all adjective phrases (ADJP) from a given sentence using a chunking grammar.\n"
      ],
      "metadata": {
        "id": "OPKKrFq5EZxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Define a chunk grammar for adjective phrases (ADJP)\n",
        "chunk_grammar = \"\"\"\n",
        "  ADJP: {<JJ.*>+}  # One or more adjectives\n",
        "\"\"\"\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The very quick brown fox jumped over the lazy dog.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Extract and print adjective phrases\n",
        "for subtree in tree.subtrees(filter=lambda t: t.label() == 'ADJP'):\n",
        "    print(subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uos0bwJEEahE",
        "outputId": "35c4abe2-7e93-4299-c8d4-ad86a25c7712"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ADJP quick/JJ)\n",
            "(ADJP lazy/JJ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.\tWrite a Python program that extracts all verb phrases (VP) from a given sentence using a chunking grammar.\n"
      ],
      "metadata": {
        "id": "a0C-9JkOEal0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Define a chunk grammar for verb phrases (VP)\n",
        "chunk_grammar = \"\"\"\n",
        "  VP: {<VB.*><NP|PP|CLAUSE>*}  # Verb followed by NP, PP, or clauses\n",
        "\"\"\"\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The cat is sleeping on the mat.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Extract and print verb phrases\n",
        "for subtree in tree.subtrees(filter=lambda t: t.label() == 'VP'):\n",
        "    print(subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV10JR4EEbcm",
        "outputId": "b5f63d40-658c-41ad-faab-1b0889bd30dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(VP is/VBZ)\n",
            "(VP sleeping/VBG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.\tWrite a Python program to extract complex noun phrases (NP) containing nested structures using chunking grammar.\n"
      ],
      "metadata": {
        "id": "ceIoFVZHEbgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.chunk import RegexpParser\n",
        "\n",
        "# Define a chunk grammar for complex noun phrases (NP) with nested structures\n",
        "chunk_grammar = \"\"\"\n",
        "  NP: {<DT>?<JJ>*<NN.*>+}  # Simple noun phrases\n",
        "      {<DT><JJ>*<NN><PP>}  # Noun phrase with a prepositional phrase\n",
        "\"\"\"\n",
        "chunk_parser = RegexpParser(chunk_grammar)\n",
        "\n",
        "# Sentence to process\n",
        "sentence = \"The quick brown fox with a shiny tail jumped over the lazy dog.\"\n",
        "\n",
        "# Tokenize and POS tag the sentence\n",
        "tokens = word_tokenize(sentence)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Apply the chunk grammar\n",
        "tree = chunk_parser.parse(tags)\n",
        "\n",
        "# Extract and print complex noun phrases\n",
        "for subtree in tree.subtrees(filter=lambda t: t.label() == 'NP'):\n",
        "    print(subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsHEgscdEcOW",
        "outputId": "5e1fd3b1-75f9-4e3a-b0bd-76ffc24abf9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(NP The/DT quick/JJ brown/NN fox/NN)\n",
            "(NP a/DT shiny/JJ tail/NN)\n",
            "(NP the/DT lazy/JJ dog/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.\tWrite a Python program using NLTK to define and apply a probabilistic grammar to generate a parse tree for a given sentence."
      ],
      "metadata": {
        "id": "sAAFhj7PEcS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI9nuYCTAjtc",
        "outputId": "07bd83b1-b17e-4eee-9bc4-d3db22a6e48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT quick/JJ brown/NN fox/NN)\n",
            "  with/IN\n",
            "  (NP a/DT shiny/JJ tail/NN)\n",
            "  jumped/VBD\n",
            "  over/IN\n",
            "  (NP the/DT lazy/JJ dog/NN)\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import PCFG\n",
        "\n",
        "# Define a probabilistic context-free grammar (PCFG)\n",
        "pcfg = PCFG.fromstring(\"\"\"\n",
        "  S -> NP VP [1.0]\n",
        "  NP -> Det N [0.5] | Det Adj N [0.5]\n",
        "  VP -> V NP [1.0]\n",
        "  Det -> 'The' [0.5] | 'a' [0.5]\n",
        "  N -> 'cat' [0.5] | 'dog' [0.5]\n",
        "  V -> 'sleeps' [0.5] | 'eats' [0.5]\n",
        "  Adj -> 'lazy' [1.0]\n",
        "\"\"\")\n",
        "\n",
        "# Create a parser\n",
        "parser = nltk.ChartParser(pcfg)\n",
        "\n",
        "# Sentence to parse\n",
        "sentence = ['The', 'cat', 'sleeps']\n",
        "\n",
        "# Parse the sentence and print the tree\n",
        "for tree in parser.parse(sentence):\n",
        "    tree.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkbha_P8FFRi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}